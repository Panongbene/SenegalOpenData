{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oJPVAjJpPkDC"
   },
   "source": [
    "# BIBLIOTEQUES ET LIBRAIRIES NECESSAIRES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "akA0Z6ihPjOH",
    "outputId": "c5b04367-0cbb-4588-8e16-188ff3395aa0"
   },
   "outputs": [],
   "source": [
    "#import scrapy\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import spacy\n",
    "import pandas\n",
    "import socket\n",
    "import requests\n",
    "from nerd import ner\n",
    "from langdetect import detect\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from webdriver_manager.firefox import GeckoDriverManager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IOy5mt46P0G1"
   },
   "source": [
    "# VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "CqmTs7daPjSe"
   },
   "outputs": [],
   "source": [
    "PAGE_INITIALE = \"https://www.presidence.sn/actualites/conseil-des-ministres\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "methaDataNameFile = \"InformationSurLesExtraitDuConseilDesMinistre.json\"\n",
    "linkDiscourtSave = \"lienDesConseilDesMinistreTeleCharger.json\"\n",
    "pathFileText = \"ConseilsFile\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "thisDiscourtIscrap = dict()\n",
    "methaDataToSave = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Mm7xWa0OQF3Y"
   },
   "source": [
    "# USEFUL FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def insertText(idDoc,textContained):\n",
    "    \"\"\"\n",
    "        use this function to create to new file for save new document haf idDoc\n",
    "        @param idDoc: text file name\n",
    "        @param textContained: text to save\n",
    "    \"\"\"\n",
    "    namefile = pathFileText+\"/\"+idDoc+\".text\"\n",
    "    try:\n",
    "        f = open(pathFileText+\"/\"+idDoc+\".text\", \"w\",encoding='utf-8')\n",
    "    except:\n",
    "        print(\"Error Operation :\")\n",
    "        return -1\n",
    "    \n",
    "    try:\n",
    "        f.write(textContained)\n",
    "    except:\n",
    "        print(\"Error Operation :\")\n",
    "        return -1\n",
    "    \n",
    "    f.close() \n",
    "    \n",
    "    return namefile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinkPageConseil(linkInitialDiscourt, numberClick = 50):\n",
    "    \"\"\"\n",
    "        use this function to get all speech links\n",
    "        @param linkInitialDiscourt: is the start link\n",
    "    \"\"\"\n",
    "    \n",
    "    linkPageDiscourt = list()\n",
    "    \n",
    "    driver = webdriver.Firefox(executable_path=GeckoDriverManager().install())\n",
    "    driver.get(linkInitialDiscourt)\n",
    "    \n",
    "    for j in range(numberClick):\n",
    "        button = driver.find_element_by_id(\"loadMoreNews\").click()\n",
    "    \n",
    "    time.sleep(60)\n",
    "    \n",
    "    lnks = driver.find_elements_by_tag_name(\"a\")\n",
    "    \n",
    "    \n",
    "    for lnk in lnks:\n",
    "        tampon = lnk.get_attribute(\"href\")\n",
    "        linkPageDiscourt.append(tampon)\n",
    "\n",
    "    driver.quit()\n",
    "    \n",
    "    return linkPageDiscourt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveJsonFile(dictionnaryToSave, nameJsonFile):\n",
    "    \"\"\"\n",
    "        use this function to save a dictionary as a json file\n",
    "        @param dictionnaryToSave: Is the dictionary containing the data\n",
    "        @param nameJsonFile: is the name of file\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        f = open(nameJsonFile, \"w\")\n",
    "        json.dump(dictionnaryToSave, f,  indent=1)\n",
    "    except:\n",
    "        print(\"Error Operation : save file error\")\n",
    "        return -1\n",
    "    \n",
    "    f.close() \n",
    "    \n",
    "    return \"FINISH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createNecessaryFile():\n",
    "    \"\"\"\n",
    "        create necessary File\n",
    "    \"\"\"\n",
    "    fileList = [methaDataNameFile, linkDiscourtSave]\n",
    "    tamponList = [pathFileText]\n",
    "    \n",
    "    for i in tamponList:\n",
    "        try:\n",
    "            os.mkdir(i)\n",
    "        except OSError:\n",
    "            print (\"Creation of the directory %s failed\" % i)\n",
    "        else:\n",
    "            print (\"Successfully created the directory %s \" % i)\n",
    "            \n",
    "    for j in fileList:\n",
    "        if(os.path.isfile(j)==False):\n",
    "            with open(j, 'w') as f:\n",
    "                f.write(\"\")\n",
    "            print (\"Successfully created the directory %s \" % j)\n",
    "        else:\n",
    "            print (\"Creation of the directory %s failed\" % j)\n",
    "        \n",
    "        \n",
    "    return \"FINISH\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def openFileAsJson(nameFile):\n",
    "    \"\"\"\n",
    "        use this function to open file as dictionnairy\n",
    "    \"\"\"\n",
    "    dataToSave = dict()\n",
    "    \n",
    "    try:\n",
    "        f = open(nameFile)\n",
    "        try:\n",
    "            if(os.path.isfile(nameFile)==True):\n",
    "                dataToSave = json.load(f)\n",
    "        except:\n",
    "            pass\n",
    "    except:\n",
    "        print(\"Error Operation : error open file or incorrect json format\")\n",
    "        return dataToSave\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    return dataToSave"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDomainName(pageUrl):\n",
    "    \"\"\"\n",
    "        give the domain name of a URL\n",
    "        @param pageUrl: is the url that we want to obtain the domain name\n",
    "    \"\"\"\n",
    "    try:\n",
    "        beginIndex = pageUrl.find(\"//\", 0, len(pageUrl))+2\n",
    "        endIndex = pageUrl.find(\"/\",beginIndex)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    return pageUrl[beginIndex:endIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHtmlPage(pageUrl):\n",
    "    \"\"\"\n",
    "        give the beautifulsup object containing the html web page from the url\n",
    "        @param utl: is the url of web page\n",
    "    \"\"\"\n",
    "    try:\n",
    "        requ = requests.get(pageUrl, allow_redirects=True)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return BeautifulSoup(\"\")\n",
    "\n",
    "    return BeautifulSoup(requ.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLanguagePage(text):\n",
    "    \"\"\"\n",
    "        This function detects the language of the text we have given it. It supports 55 languages\n",
    "        @param text: is the text whose language we want to detect\n",
    "    \"\"\"\n",
    "    language = \"\"\n",
    "    try:\n",
    "        language = detect(text)\n",
    "    except:\n",
    "        return \"\"\n",
    "    \n",
    "    return language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLink(soup, domainname):\n",
    "    \"\"\"\n",
    "        give all link in beautiful soup html object\n",
    "        return the list of link\n",
    "        @param soup: is a soup variable containing html page\n",
    "        @param domainname: is the domaine of web page\n",
    "    \"\"\"\n",
    "    urlInThePage = list()\n",
    "    \n",
    "    if(len(soup) == 0):\n",
    "        return urlInThePage\n",
    "    \n",
    "    for link in soup.findAll('a'):\n",
    "        linkValues = link.get('href')\n",
    "        if(type(linkValues)!=str or len(linkValues)==0):\n",
    "            continue\n",
    "        \n",
    "        if(linkValues[0]==\"/\"):\n",
    "            urlInThePage.append(\"http://\"+domainname+linkValues)\n",
    "        else:\n",
    "            if(\"#\" in linkValues):\n",
    "                beginIndex = linkValues.find(\"#\", 0, len(linkValues))\n",
    "                linkValues = linkValues[0:beginIndex]\n",
    "                if(len(linkValues)!=0):\n",
    "                    urlInThePage.append(linkValues)\n",
    "            else:\n",
    "                urlInThePage.append(linkValues)\n",
    "\n",
    "    return urlInThePage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getIp(pageUrl):\n",
    "    \"\"\"\n",
    "        return the ip address of the url pageUrl\n",
    "        @param pageUrl: the url we want to get the IP address\n",
    "    \"\"\"\n",
    "    ip=\"\"\n",
    "    pageUrl = getDomainName(pageUrl)\n",
    "    try:\n",
    "        ip = socket.gethostbyname(pageUrl)\n",
    "    except socket.gaierror:\n",
    "        ip = \"\"\n",
    "\n",
    "    return ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextOfPage(soup):\n",
    "    \"\"\"\n",
    "        This page extracts useful texts from your beautifulsoup object\n",
    "        @param soup:\n",
    "    \"\"\"\n",
    "\n",
    "    textSoup = str(soup)\n",
    "\n",
    "    textSoup = str(soup)\n",
    "    for link in soup.findAll('script'):\n",
    "        textSoup = textSoup.replace(str(link),\" \")\n",
    "\n",
    "    for link in soup.findAll('style'):\n",
    "        textSoup = textSoup.replace(str(link),\" \")    \n",
    "\n",
    "    beginIndex = 10\n",
    "    endIndex = 100\n",
    "\n",
    "    while(beginIndex>=0 and endIndex>=0):\n",
    "        beginIndex = textSoup.find(\"<\", 0, len(textSoup))\n",
    "        endIndex = textSoup.find(\">\",beginIndex)+1\n",
    "\n",
    "        textSoup = textSoup.replace(textSoup[beginIndex:endIndex],\"\")\n",
    "    \n",
    "    return textSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTextOfPageConseilsDesMinistre(ConseilsSoup):\n",
    "    \"\"\"\n",
    "        This page extracts useful texts from your beautifulsoup object\n",
    "        @param soup:\n",
    "    \"\"\"\n",
    "\n",
    "    textSoup = \"\"\n",
    "    \n",
    "    textIsConseil = ConseilsSoup.findAll('h1',{ \"class\" : \"mb-40\" })\n",
    "    \n",
    "    if(len(textIsConseil)!=0):\n",
    "        if('Conseil' in textIsConseil[0].text or 'conseil' in textIsConseil[0].text ):\n",
    "            textSoup = ConseilsSoup.findAll('div',{ \"class\" : \"container-narrow mx-auto mt-50\" })[0]\n",
    "            \n",
    "            textSoup = textIsConseil[0].text+\"\\n\" + str(textSoup)\n",
    "            for link in ConseilsSoup.findAll('script'):\n",
    "                textSoup = textSoup.replace(str(link),\" \")\n",
    "\n",
    "            for link in ConseilsSoup.findAll('style'):\n",
    "                textSoup = textSoup.replace(str(link),\" \")    \n",
    "\n",
    "            beginIndex = 10\n",
    "            endIndex = 100\n",
    "\n",
    "            while(beginIndex>=0 and endIndex>=0):\n",
    "                beginIndex = textSoup.find(\"<\", 0, len(textSoup))\n",
    "                endIndex = textSoup.find(\">\",beginIndex)+1\n",
    "\n",
    "                textSoup = textSoup.replace(textSoup[beginIndex:endIndex],\"\")\n",
    "                \n",
    "    return textSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "xCcEYZi7P-vh"
   },
   "outputs": [],
   "source": [
    "def getTitle(soup):\n",
    "    \"\"\"\n",
    "        we use this function to get the title\n",
    "        @param soup: is a soup variable containing an html page\n",
    "    \"\"\"\n",
    "    title=\"\"\n",
    "    try:\n",
    "        title=soup.title.string\n",
    "    except :\n",
    "        title=\"\"\n",
    "    \n",
    "    return title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCRAPING WEB SITE :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessingScrapingWebSite(urlPage):\n",
    "    \"\"\"\n",
    "        scraping and preprocessing the web page with urlPage url\n",
    "        @param urlPage: URL of the page considered\n",
    "    \"\"\"\n",
    "    soup = getHtmlPage(urlPage)\n",
    "    domainName = getDomainName(urlPage)\n",
    "    ipAdress = getIp(urlPage)\n",
    "    \n",
    "    linkPage = getLink(soup, domainName)\n",
    "    textPage = getTextOfPageConseilsDesMinistre(soup)\n",
    "    title = getTitle(soup)\n",
    "    language = getLanguagePage(textPage)\n",
    "    \n",
    "    return domainName, ipAdress, linkPage, title, language, textPage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping Ciblé"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapingCible(listOfUrl):\n",
    "    \"\"\"\n",
    "        This function scrapes all the web pages of listOfUrl\n",
    "        @param listOfUrl: URL list containing the URLs of the web page we want to extract\n",
    "    \"\"\"\n",
    "    \n",
    "    resultScraping = dict()\n",
    "    k = 0\n",
    "    for urlPage in listOfUrl:\n",
    "        domainName, ipAdress, linkPage, title, language, textPage = preprocessingScrapingWebSite(urlPage)\n",
    "        resultScraping[k] = {\"domainName\":domainName, \"ipAdress\":ipAdress, \"urlPage\":urlPage, \"title\":title, \"language\":language, \"textPage\":textPage}\n",
    "        k+=1\n",
    "        \n",
    "    return resultScraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET CONSEILS DES MINISTRES COMMUNIQUES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current firefox version is 88.0\n",
      "Get LATEST driver version for 88.0\n",
      "Driver [/home/panongbene/.wdm/drivers/geckodriver/linux64/v0.29.1/geckodriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "linkPage = getLinkPageConseil(PAGE_INITIALE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "testest = scrapingCible(linkPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "297"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(testest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the directory ConseilsFile \n",
      "Successfully created the directory InformationSurLesExtraitDuConseilDesMinistre.json \n",
      "Successfully created the directory lienDesConseilDesMinistreTeleCharger.json \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'FINISH'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "createNecessaryFile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 0\n",
    "for i in testest:\n",
    "    if(len(testest[i][\"textPage\"])>10):\n",
    "        methaDataToSave[k+1] = {\"domainName\":testest[i][\"domainName\"], \"ipAdress\":testest[i][\"ipAdress\"], \"urlPage\":testest[i][\"urlPage\"], \"title\":testest[i][\"title\"], \"language\":testest[i][\"language\"], \"textFile\":insertText(str(k+1),testest[i][\"textPage\"])}\n",
    "        thisDiscourtIscrap[k] = testest[i][\"urlPage\"]\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FINISH'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saveJsonFile(thisDiscourtIscrap, linkDiscourtSave)\n",
    "saveJsonFile(methaDataToSave, methaDataNameFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UPDATE DOWNLOADS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#methaDataNameFile = openFileAsJson(methaDataNameFile)\n",
    "thisDiscourtIscrap = openFileAsJson(linkDiscourtSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "====== WebDriver manager ======\n",
      "Current firefox version is 88.0\n",
      "Get LATEST driver version for 88.0\n",
      "Driver [/home/panongbene/.wdm/drivers/geckodriver/linux64/v0.29.1/geckodriver] found in cache\n"
     ]
    }
   ],
   "source": [
    "linkPage = getLinkPageConseil(PAGE_INITIALE, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in thisDiscourtIscrap:\n",
    "    if(i in linkPage):\n",
    "        linkPage.remove(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "testest = scrapingCible(linkPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = len(methaDataToSave)\n",
    "for i in testest:\n",
    "    if(len(testest[i][\"textPage\"])>10):\n",
    "        methaDataToSave[k+1] = {\"domainName\":testest[i][\"domainName\"], \"ipAdress\":testest[i][\"ipAdress\"], \"urlPage\":testest[i][\"urlPage\"], \"title\":testest[i][\"title\"], \"language\":testest[i][\"language\"], \"textFile\":insertText(str(k+1),testest[i][\"textPage\"])}\n",
    "        thisDiscourtIscrap[k] = testest[i][\"urlPage\"]\n",
    "        k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saveJsonFile(thisDiscourtIscrap, linkDiscourtSave)\n",
    "saveJsonFile(methaDataToSave, methaDataNameFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "scrapingCode.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
